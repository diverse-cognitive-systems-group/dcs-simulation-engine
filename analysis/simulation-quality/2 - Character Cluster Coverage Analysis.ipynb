{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd646b9",
   "metadata": {},
   "source": [
    "*üöß NOTICE: This is a W.I.P.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8cb46b",
   "metadata": {},
   "source": [
    "# Character Cluster Coverage Analysis\n",
    "\n",
    "**Purpose**: To provide a standard evaluation tool for measuring the scope and diversity of the characters represented in our character database without over-reliance on dimensional coverage. Specifically, what clusters do they cover and how broadly? What is not covered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89af19",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58338241",
   "metadata": {},
   "source": [
    "*Note: if additional packages are needed add them to the pyproject.toml [analysis] section using:*\n",
    "```sh\n",
    "uv add <package> --optional analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install analysis extras\n",
    "!uv sync --extra analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os, json, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a86d5",
   "metadata": {},
   "source": [
    "### 1. Load characters -> get hid, long_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535cc5ec",
   "metadata": {},
   "source": [
    "Load character data from characters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CHARACTER_DATA_FPATH = Path(\"database_seeds\") / \"characters.json\"\n",
    "\n",
    "with open(CHARACTER_DATA_FPATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# characters.json might be a list[dict] or dict[hid -> dict]\n",
    "if isinstance(raw, dict):\n",
    "    records = []\n",
    "    for hid, obj in raw.items():\n",
    "        obj = dict(obj)\n",
    "        obj.setdefault(\"hid\", hid)\n",
    "        records.append(obj)\n",
    "else:\n",
    "    records = raw\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# sanity check: what columns exist?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cda07",
   "metadata": {},
   "source": [
    "Extract what we need: hid, long_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust if your schema differs (e.g. \"id\" instead of \"hid\", \"description\" instead of \"long_description\")\n",
    "HID_COL = \"hid\"\n",
    "DESC_COL = \"long_description\"\n",
    "\n",
    "missing = [c for c in [HID_COL, DESC_COL] if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(\n",
    "        f\"Missing expected columns: {missing}. Available columns: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "df = df[[HID_COL, DESC_COL]].copy()\n",
    "\n",
    "# Drop blanks\n",
    "df[DESC_COL] = df[DESC_COL].astype(str).fillna(\"\").str.strip()\n",
    "df = df[df[DESC_COL].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c52549",
   "metadata": {},
   "source": [
    "Normalize descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)  # collapse spaces/tabs\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)  # collapse excessive newlines\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "df[\"long_description_norm\"] = df[DESC_COL].map(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca6144",
   "metadata": {},
   "source": [
    "Optional: add a stable header so embeddings ‚Äúknow‚Äù the entity id (useful when descriptions are short-ish):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dac7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embed_text\"] = df.apply(\n",
    "    lambda r: f\"HID: {r[HID_COL]}\\nDESCRIPTION:\\n{r['long_description_norm']}\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740dd14",
   "metadata": {},
   "source": [
    "### 2. Get OpenAI embeddings for long_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY not set in environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70485eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"text-embedding-3-large\"  # or \"text-embedding-3-small\"\n",
    "\n",
    "\n",
    "def embed_texts(texts, model=EMBED_MODEL, batch_size=128):\n",
    "    vectors = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        resp = client.embeddings.create(model=model, input=batch)\n",
    "        vectors.extend([d.embedding for d in resp.data])\n",
    "    return np.array(vectors, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embed_texts(df[\"embed_text\"].tolist())\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b58948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = list(emb)  # convenient but large\n",
    "# Better: save separately\n",
    "np.save(\"character_embeddings.npy\", emb)\n",
    "df[[HID_COL, \"long_description_norm\"]].to_parquet(\n",
    "    \"character_texts.parquet\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b621e",
   "metadata": {},
   "source": [
    "Sanity check: do the embeddings look reasonable? (e.g. nearest neighbor search for a few examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(emb)\n",
    "\n",
    "\n",
    "def top_neighbors(i, k=10):\n",
    "    sims = S[i].copy()\n",
    "    sims[i] = -1\n",
    "    nn = np.argsort(-sims)[:k]\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"hid\": df.loc[nn, HID_COL].values,\n",
    "            \"similarity\": sims[nn],\n",
    "            \"preview\": df.loc[nn, \"long_description_norm\"].str[:120].values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "top_neighbors(0, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
